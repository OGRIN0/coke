{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "folder_path = \"/Users/amarnath/coke\"\n",
    "loaders = [PyPDFLoader(os.path.join(folder_path, file)) for file in os.listdir(folder_path) if file.endswith(\".pdf\")]\n",
    "documents = []\n",
    "for loader in loaders:\n",
    "    documents.extend(loader.load())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Loaded API key: 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\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import langchain\n",
    "import pinecone\n",
    "import langchain.document_loaders as loaders\n",
    "dir(loaders)\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores  import Pinecone\n",
    "from  langchain.llms import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  \n",
    "secret_key = os.getenv(\"SECRET_KEY\")\n",
    "print(secret_key)\n",
    "\n",
    "def read_doc(directory):\n",
    "    file_loader=PyPDFDirectoryLoader(directory)\n",
    "    documents=file_loader.load()\n",
    "    return documents\n",
    "\n",
    "doc=read_doc('documents/')\n",
    "def chunk_data(docs,chunk_size=800,chunk_overlap=50):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=chunk_size,chunk_overlap=chunk_overlap)\n",
    "    doc=text_splitter.split_documents(docs)\n",
    "    return docs\n",
    "\n",
    "documents = chunk_data(docs=doc)\n",
    "\n",
    "\n",
    "\n",
    "load_dotenv(dotenv_path=\"/Users/amarnath/coke/a.env\")\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(\"Loaded API key:\", api_key)\n",
    "\n",
    "embeddings = OpenAIEmbeddings(api_key=api_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "vectors = embeddings = model.encode(\"How are you?\")\n",
    "len(vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'openai' has no attribute 'error'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m vectors\u001b[38;5;241m=\u001b[39m \u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHow are you?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/coke/.env/lib/python3.11/site-packages/langchain_community/embeddings/openai.py:700\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_query\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21membed_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    692\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call out to OpenAI's embedding endpoint for embedding query text.\u001b[39;00m\n\u001b[1;32m    693\u001b[0m \n\u001b[1;32m    694\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;124;03m        Embedding for the text.\u001b[39;00m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 700\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/coke/.env/lib/python3.11/site-packages/langchain_community/embeddings/openai.py:671\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[0;34m(self, texts, chunk_size)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[1;32m    670\u001b[0m engine \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment)\n\u001b[0;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/coke/.env/lib/python3.11/site-packages/langchain_community/embeddings/openai.py:497\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[0;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[1;32m    495\u001b[0m batched_embeddings: List[List[\u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n\u001b[0;32m--> 497\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43membed_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_chunk_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invocation_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    503\u001b[0m         response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mdict()\n",
      "File \u001b[0;32m~/coke/.env/lib/python3.11/site-packages/langchain_community/embeddings/openai.py:121\u001b[0m, in \u001b[0;36membed_with_retry\u001b[0;34m(embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_openai_v1():\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 121\u001b[0m retry_decorator \u001b[38;5;241m=\u001b[39m \u001b[43m_create_retry_decorator\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_embed_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    125\u001b[0m     response \u001b[38;5;241m=\u001b[39m embeddings\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/coke/.env/lib/python3.11/site-packages/langchain_community/embeddings/openai.py:61\u001b[0m, in \u001b[0;36m_create_retry_decorator\u001b[0;34m(embeddings)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Wait 2^x * 1 second between each retry starting with\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# retry_min_seconds seconds, then up to retry_max_seconds seconds,\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# then retry_max_seconds seconds afterwards\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# retry_min_seconds and retry_max_seconds are optional arguments of\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# OpenAIEmbeddings\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retry(\n\u001b[1;32m     53\u001b[0m     reraise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     54\u001b[0m     stop\u001b[38;5;241m=\u001b[39mstop_after_attempt(embeddings\u001b[38;5;241m.\u001b[39mmax_retries),\n\u001b[1;32m     55\u001b[0m     wait\u001b[38;5;241m=\u001b[39mwait_exponential(\n\u001b[1;32m     56\u001b[0m         multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39membeddings\u001b[38;5;241m.\u001b[39mretry_min_seconds,\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39membeddings\u001b[38;5;241m.\u001b[39mretry_max_seconds,\n\u001b[1;32m     59\u001b[0m     ),\n\u001b[1;32m     60\u001b[0m     retry\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m---> 61\u001b[0m         retry_if_exception_type(\u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[38;5;241m.\u001b[39mTimeout)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;241m|\u001b[39m retry_if_exception_type(openai\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mAPIError)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;241m|\u001b[39m retry_if_exception_type(openai\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mAPIConnectionError)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;241m|\u001b[39m retry_if_exception_type(openai\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mRateLimitError)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;241m|\u001b[39m retry_if_exception_type(openai\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mServiceUnavailableError)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     ),\n\u001b[1;32m     67\u001b[0m     before_sleep\u001b[38;5;241m=\u001b[39mbefore_sleep_log(logger, logging\u001b[38;5;241m.\u001b[39mWARNING),\n\u001b[1;32m     68\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'openai' has no attribute 'error'"
     ]
    }
   ],
   "source": [
    "vectors= embeddings.embed_query(\"How are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_doc(directory):\n",
    "    file_loader=PyPDFDirectoryLoader(directory)\n",
    "    documents=file_loader.load()\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=read_doc('documents/')\n",
    "def chunk_data(docs,chunk_size=800,chunk_overlap=50):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=chunk_size,chunk_overlap=chunk_overlap)\n",
    "    doc=text_splitter.split_documents(docs)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = chunk_data(docs=doc)\n",
    "len(documents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
